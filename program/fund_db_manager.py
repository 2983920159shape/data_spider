import requests
import sqlite3
import pandas as pd
import os
import re
import json
from datetime import datetime, timedelta, timezone


def fetch_fund_data(fund_code):
    """æŠ“å–åŸºé‡‘å‡€å€¼æ•°æ®"""
    url = f"https://fundgz.1234567.com.cn/js/{fund_code}.js"
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, timeout=20, headers=headers)
        match = re.search(r'jsonpgz\((.*)\);', response.text)
        if match:
            data = json.loads(match.group(1))
            return {
                'åŸºé‡‘ä»£ç ': data['fundcode'],
                'æ—¥æœŸ': data['gztime'].split(' ')[0],
                'å•ä½å‡€å€¼': float(data['gsz']),
                'ç´¯è®¡å‡€å€¼': float(data['gsz']),
                'æ—¥æ¶¨è·Œå¹…': float(data['gszzl'])
            }
    except Exception as e:
        print(f"æŠ“å–åŸºé‡‘ {fund_code} å¤±è´¥: {e}")
    return None


def get_beijing_time():
    """è·å–ç²¾å‡†çš„åŒ—äº¬æ—¶é—´"""
    tz_beijing = timezone(timedelta(hours=8))
    return datetime.now(tz_beijing)


def main():
    db_path = os.path.join('output', 'funds_manager.db')
    log_path = os.path.join('output', 'daily_sync.log')
    csv_path = os.path.join('output', 'funds_history_export.csv')

    if not os.path.exists('output'):
        os.makedirs('output')

    conn = sqlite3.connect(db_path)

    # 1. ç¡®ä¿è¡¨ç»“æ„ï¼ˆä½¿ç”¨ä¸­æ–‡åˆ—åï¼‰
    conn.execute('''CREATE TABLE IF NOT EXISTS fund_history 
                    (åŸºé‡‘ä»£ç  TEXT, æ—¥æœŸ TEXT, å•ä½å‡€å€¼ REAL, 
                     ç´¯è®¡å‡€å€¼ REAL, æ—¥æ¶¨è·Œå¹… REAL, 
                     PRIMARY KEY (åŸºé‡‘ä»£ç , æ—¥æœŸ))''')

    # æ£€æŸ¥è¿è¡Œå‰çŠ¶æ€
    before_df = pd.read_sql("SELECT * FROM fund_history", conn)
    before_count = len(before_df)

    # 2. æ‰§è¡ŒæŠ“å–ä»»åŠ¡
    bj_now = get_beijing_time()
    fund_list = ['023350']
    print(f"[{bj_now.strftime('%Y-%m-%d %H:%M:%S')}] å¯åŠ¨äº‘ç«¯åŒæ­¥ç¨‹åº...")

    results = []
    for code in fund_list:
        res = fetch_fund_data(code)
        if res:
            results.append(res)

    # 3. å†™å…¥æ•°æ®åº“
    if results:
        df_new = pd.DataFrame(results)
        cursor = conn.cursor()
        for _, row in df_new.iterrows():
            cursor.execute('''
                INSERT OR IGNORE INTO fund_history (åŸºé‡‘ä»£ç , æ—¥æœŸ, å•ä½å‡€å€¼, ç´¯è®¡å‡€å€¼, æ—¥æ¶¨è·Œå¹…)
                VALUES (?, ?, ?, ?, ?)
            ''', (row['åŸºé‡‘ä»£ç '], row['æ—¥æœŸ'], row['å•ä½å‡€å€¼'], row['ç´¯è®¡å‡€å€¼'], row['æ—¥æ¶¨è·Œå¹…']))
        conn.commit()

    # 4. è·å–æœ€æ–°æ•°æ®å¹¶å¯¼å‡º CSV
    full_df = pd.read_sql("SELECT * FROM fund_history ORDER BY æ—¥æœŸ DESC", conn)
    after_count = len(full_df)
    new_records = after_count - before_count

    # å¯¼å‡ºä¸­æ–‡åˆ—åçš„ CSV
    full_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    conn.close()

    # 5. ç”ŸæˆæŠ¥å‘Š
    report = (
            f"\n" + "=" * 40 + "\n"
                               f"ğŸ“Š æ•°æ®åŒæ­¥æŠ¥å‘Š | {bj_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
                               f"âœ… æœ¬æ¬¡æ–°å¢è®°å½•: {new_records} æ¡\n"
                               f"ğŸ“ˆ æ•°æ®åº“æ€»æ¡æ•°: {after_count} æ¡\n"
                               f"ğŸ“… çŠ¶æ€åé¦ˆ: {'æ•°æ®æ›´æ–°æˆåŠŸ' if new_records > 0 else 'ä»Šæ—¥æš‚æ— æ–°æ•°æ®æˆ–æŠ“å–è¶…æ—¶'}\n"
                               f"========================================\n"
    )
    print(report)
    with open(log_path, 'a', encoding='utf-8') as f:
        f.write(report)


if __name__ == "__main__":
    main()