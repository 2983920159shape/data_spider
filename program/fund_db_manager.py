import requests
import sqlite3
import pandas as pd
import os
import re
import json
from datetime import datetime, timedelta, timezone


def fetch_fund_data(fund_code):
    """æŠ“å–åŸºé‡‘å‡€å€¼æ•°æ®"""
    url = f"https://fundgz.1234567.com.cn/js/{fund_code}.js"
    try:
        # å¢åŠ  User-Agent ä¼ªè£…ï¼Œæé«˜äº‘ç«¯è®¿é—®æˆåŠŸç‡
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, timeout=25, headers=headers)
        match = re.search(r'jsonpgz\((.*)\);', response.text)
        if match:
            data = json.loads(match.group(1))
            return {
                'fund_code': data['fundcode'],
                'date': data['gztime'].split(' ')[0],
                'unit_value': float(data['gsz']),
                'total_value': float(data['gsz']),
                'growth_rate': float(data['gszzl'])
            }
    except Exception as e:
        print(f"æŠ“å–åŸºé‡‘ {fund_code} å¤±è´¥: {e}")
    return None


def get_beijing_time():
    """è·å–ç²¾å‡†çš„åŒ—äº¬æ—¶é—´"""
    # å¼ºåˆ¶åç§» UTC+8
    tz_beijing = timezone(timedelta(hours=8))
    return datetime.now(tz_beijing)


def main():
    db_path = os.path.join('output', 'funds_manager.db')
    log_path = os.path.join('output', 'daily_sync.log')
    csv_path = os.path.join('output', 'funds_history_export.csv')

    if not os.path.exists('output'):
        os.makedirs('output')

    conn = sqlite3.connect(db_path)

    # ä¿æŒæ—§çš„è‹±æ–‡åˆ—åç»“æ„
    conn.execute('''CREATE TABLE IF NOT EXISTS fund_history 
                    (fund_code TEXT, date TEXT, unit_value REAL, 
                     total_value REAL, growth_rate REAL, 
                     PRIMARY KEY (fund_code, date))''')

    # æ£€æŸ¥è¿è¡Œå‰æ•°æ®é‡
    before_df = pd.read_sql("SELECT * FROM fund_history", conn)
    before_count = len(before_df)

    # è·å–åŒ—äº¬æ—¶é—´å¹¶æ‰“å°æŠ¥å‘Šå¤´éƒ¨
    bj_now = get_beijing_time()
    print(f"[{bj_now.strftime('%Y-%m-%d %H:%M:%S')}] å¯åŠ¨äº‘ç«¯åŒæ­¥ç¨‹åº...")

    # æ‰§è¡ŒæŠ“å–
    fund_list = ['023350']
    results = []
    for code in fund_list:
        res = fetch_fund_data(code)
        if res:
            results.append(res)

    # å†™å…¥å¢é‡æ•°æ®
    if results:
        df_new = pd.DataFrame(results)
        cursor = conn.cursor()
        for _, row in df_new.iterrows():
            cursor.execute('''
                INSERT OR IGNORE INTO fund_history (fund_code, date, unit_value, total_value, growth_rate)
                VALUES (?, ?, ?, ?, ?)
            ''', (row['fund_code'], row['date'], row['unit_value'], row['total_value'], row['growth_rate']))
        conn.commit()

    # åˆ·æ–°çŠ¶æ€å¹¶å¯¼å‡º CSV
    full_df = pd.read_sql("SELECT * FROM fund_history ORDER BY date DESC", conn)
    after_count = len(full_df)
    new_records = after_count - before_count
    full_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    conn.close()

    # ç”ŸæˆæŠ¥å‘Šå†…å®¹
    report = (
            f"\n" + "=" * 40 + "\n"
                               f"ğŸ“Š æ•°æ®åŒæ­¥æŠ¥å‘Š | {bj_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
                               f"âœ… æœ¬æ¬¡æ–°å¢è®°å½•: {new_records} æ¡\n"
                               f"ğŸ“ˆ æ•°æ®åº“æ€»æ¡æ•°: {after_count} æ¡\n"
                               f"ğŸ“… çŠ¶æ€åé¦ˆ: {'æ•°æ®æ›´æ–°æˆåŠŸ' if new_records > 0 else 'ä»Šæ—¥æš‚æ— æ–°æ•°æ®æˆ–æŠ“å–è¶…æ—¶'}\n"
                               f"========================================\n"
    )
    print(report)
    with open(log_path, 'a', encoding='utf-8') as f:
        f.write(report)


if __name__ == "__main__":
    main()