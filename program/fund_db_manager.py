import requests
import sqlite3
import pandas as pd
import os
import json
import time
import math
from datetime import datetime, timedelta, timezone


def get_beijing_time():
    """ã€åŠŸèƒ½ã€‘è·å–å½“å‰çš„åŒ—äº¬æ—¶é—´ï¼Œç”¨äºæ—¥å¿—è®°å½•å’Œæ—¶é—´æˆ³"""
    # è®¾ç½®ä¸œå…«åŒºæ—¶åŒº
    tz_beijing = timezone(timedelta(hours=8))
    return datetime.now(tz_beijing)


def main():
    # --- 1. è·¯å¾„è‡ªåŠ¨å¯¹é½æ¨¡å— ---
    # è·å–å½“å‰æ‰§è¡Œä»£ç æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # è·å–æ ¹ç›®å½•ï¼ˆå³ program çš„ä¸Šä¸€çº§ï¼‰ï¼Œç¡®ä¿ output æ–‡ä»¶å¤¹ä¸ program åŒçº§
    root_dir = os.path.dirname(current_dir)
    # å®šä¹‰è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
    output_dir = os.path.join(root_dir, 'output')

    # å¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼ˆæ¯”å¦‚ä½ åˆšåˆ äº†ï¼‰ï¼Œç¨‹åºä¼šè‡ªåŠ¨åˆ›å»ºå®ƒ
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # å®šä¹‰ä¸‰ä¸ªæ ¸å¿ƒæ–‡ä»¶çš„å­˜æ”¾è·¯å¾„
    db_path = os.path.join(output_dir, 'funds_manager.db')
    csv_path = os.path.join(output_dir, 'funds_history_export.csv')
    log_path = os.path.join(output_dir, 'daily_sync.log')

    # --- 2. æ•°æ®åº“å‡†å¤‡æ¨¡å— ---
    # è¿æ¥æ•°æ®åº“ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»ºï¼‰
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    # åˆ›å»ºè¡¨ï¼šä½¿ç”¨ä¸­æ–‡åˆ—åï¼Œå¹¶å°† (åŸºé‡‘ä»£ç , æ—¥æœŸ) è®¾ä¸ºä¸»é”®ï¼ˆPRIMARY KEYï¼‰
    # è¿™æ˜¯å®ç°â€œå¢é‡æ›´æ–°â€çš„æ ¸å¿ƒï¼šä¸»é”®ä¿è¯äº†åŒä¸€ä¸ªåŸºé‡‘åœ¨åŒä¸€ä¸ªæ—¥æœŸåªèƒ½æœ‰ä¸€æ¡è®°å½•
    cursor.execute('''CREATE TABLE IF NOT EXISTS fund_history 
                    (åŸºé‡‘ä»£ç  TEXT, æ—¥æœŸ TEXT, å•ä½å‡€å€¼ REAL, ç´¯è®¡å‡€å€¼ REAL, æ—¥æ¶¨è·Œå¹… REAL, 
                     PRIMARY KEY (åŸºé‡‘ä»£ç , æ—¥æœŸ))''')

    # --- 3. æŠ•çŸ³é—®è·¯ï¼šåˆå§‹åŒ–è·å–æ€»æ•° ---
    fund_code = '023350'
    page_size = 20  # é‡‡ç”¨ç½‘é¡µé»˜è®¤çš„æ¯é¡µ20æ¡ï¼Œæœ€ç¨³å¥ï¼Œä¸å®¹æ˜“è¢«å°IP
    headers = {
        'Referer': f'https://fundf10.eastmoney.com/jjjz_{fund_code}.html',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }

    # å…ˆè¯·æ±‚ä¸€æ¬¡ç¬¬ä¸€é¡µï¼Œç›®çš„æ˜¯ä¸ºäº†çœ‹æœåŠ¡å™¨ä¸Šä¸€å…±æœ‰å¤šå°‘æ¡æ•°æ®ï¼ˆTotalCountï¼‰
    first_url = f"https://api.fund.eastmoney.com/f10/lsjz?fundCode={fund_code}&pageIndex=1&pageSize={page_size}"
    try:
        res = requests.get(first_url, headers=headers, timeout=20)
        first_data = res.json()
        # æå–æ€»è®°å½•æ•°
        total_records = int(first_data['TotalCount'])
        # æ ¸å¿ƒç®—æ³•ï¼šæ€»é¡µæ•° = æ€»è®°å½•æ•° / æ¯é¡µæ¡æ•° (å‘ä¸Šå–æ•´)
        total_pages = math.ceil(total_records / page_size)
        print(f"æ£€æµ‹åˆ°åŸºé‡‘ {fund_code} å…±æœ‰ {total_records} æ¡æ•°æ®ï¼Œç¨‹åºå°†åˆ† {total_pages} é¡µè¿›è¡Œå…¨é‡æ‰«æã€‚")
    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ¥å£é“¾æ¥: {e}")
        return

    # --- 4. è‡ªåŠ¨åŒ–åˆ†é¡µæŠ“å–æ¨¡å— ---
    new_count = 0  # è®¡æ•°å™¨ï¼šè®°å½•æœ¬æ¬¡è¿è¡ŒçœŸæ­£å¾€æ•°æ®åº“é‡Œæ–°å¡äº†å¤šå°‘æ¡
    for page in range(1, total_pages + 1):
        print(f"[{get_beijing_time().strftime('%Y-%m-%d %H:%M:%S')}] æ­£åœ¨åŒæ­¥ç¬¬ {page}/{total_pages} é¡µ...")
        url = f"https://api.fund.eastmoney.com/f10/lsjz?fundCode={fund_code}&pageIndex={page}&pageSize={page_size}"

        try:
            response = requests.get(url, headers=headers, timeout=20)
            data = response.json()
            # è·å–å½“å‰é¡µçš„æ˜ç»†åˆ—è¡¨
            records = data['Data']['LSJZList']

            for item in records:
                # INSERT OR IGNOREï¼šè¿™æ˜¯å®ç°â€œå…¨é‡+å¢é‡â€çš„å…³é”®é€»è¾‘
                # å¦‚æœæ•°æ®åº“é‡Œå·²ç»æœ‰äº†è¯¥æ—¥æœŸï¼Œå°±å¿½ç•¥ï¼ˆIGNOREï¼‰ï¼›æ²¡æœ‰å°±æ’å…¥
                cursor.execute('''
                    INSERT OR IGNORE INTO fund_history VALUES (?, ?, ?, ?, ?)
                ''', (fund_code, item['FSRQ'], item['DWJZ'], item['LJJZ'], item['JZZZL']))

                # cursor.rowcount > 0 è¡¨ç¤ºè¿™ä¸€è¡Œæ˜¯çœŸæ­£æ–°æ’å…¥æˆåŠŸçš„
                if cursor.rowcount > 0:
                    new_count += 1

            # æ¯ä¸€é¡µå¤„ç†å®Œæäº¤ä¸€æ¬¡äº‹åŠ¡ï¼Œä¿å­˜æ•°æ®
            conn.commit()

            # é«˜æ•ˆé‡‡é›†ï¼šå¬ä½ çš„ï¼Œåªç­‰ 1 ç§’ï¼Œæ—¢å°Šé‡æœåŠ¡å™¨åˆä¸æ‹–æ³¥å¸¦æ°´
            time.sleep(1)

        except Exception as e:
            print(f"ç¬¬ {page} é¡µåŒæ­¥æ—¶å‘ç”Ÿçªå‘é”™è¯¯: {e}")
            break

    # --- 5. æ•°æ®å¯¼å‡ºæ¨¡å— ---
    # ä»æ•°æ®åº“è¯»å–æ‰€æœ‰è®°å½•ï¼Œå¹¶æŒ‰æ—¥æœŸå€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨ä¸Šé¢ï¼‰
    full_df = pd.read_sql("SELECT * FROM fund_history ORDER BY æ—¥æœŸ DESC", conn)
    # å¯¼å‡º CSVï¼šä½¿ç”¨ utf-8-sig ç¼–ç ï¼Œç¡®ä¿ç”¨ Excel æ‰“å¼€ä¸­æ–‡ä¸ä¹±ç 
    full_df.to_csv(csv_path, index=False, encoding='utf-8-sig')

    total_count = len(full_df)
    conn.close()

    # --- 6. æ—¥å¿—æŠ¥å‘Šæ¨¡å— ---
    bj_now = get_beijing_time()
    report = (
            f"\n" + "=" * 40 + "\n"
                               f"ğŸ“Š æ•°æ®åŒæ­¥æŠ¥å‘Š | {bj_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
                               f"âœ… çŠ¶æ€åé¦ˆ: å…¨è‡ªåŠ¨åˆ†é¡µåŒæ­¥å®Œæˆ\n"
                               f"ğŸ†• æœ¬æ¬¡æ–°å¢è®°å½•: {new_count} æ¡\n"
                               f"ğŸ“ˆ æ•°æ®åº“æ€»æ¡æ•°: {total_count} æ¡\n"
                               f"========================================\n"
    )
    # æ‰“å°åˆ°å±å¹•ï¼ŒåŒæ—¶è¿½åŠ å†™å…¥åˆ° daily_sync.log æ–‡ä»¶ä¸­
    print(report)
    with open(log_path, 'a', encoding='utf-8') as f:
        f.write(report)


if __name__ == "__main__":
    main()